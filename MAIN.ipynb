{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNiyr8ZabyEB0bfiN5LbqwC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manvi1718/Emotion_Analysis/blob/main/MAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emotion analysis"
      ],
      "metadata": {
        "id": "w13fqiwkuyH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting dataset with kaggle\n"
      ],
      "metadata": {
        "id": "T8WayqqMu1Kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"annmittal\"\n",
        "os.environ[\"KAGGLE_KEY\"] =\"b36a820c483a21bd0633e9b284bbc42c\"\n",
        "\n",
        "!kaggle datasets download -d shawon10/ckplus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdAx2qciuz9p",
        "outputId": "bd4e01fa-1cd4-4400-801e-9137755cb359"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ckplus.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ckplus.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z73bEnCvFoy",
        "outputId": "45a046fe-e8bc-4070-91ec-784aa2589e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ckplus.zip\n",
            "replace CK+48/anger/S010_004_00000017.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading libraries"
      ],
      "metadata": {
        "id": "c9VZAbd1vkta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torch.utils import data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "#import albumentations\n",
        "#from albumentations import pytorch as AT\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#import csv\n",
        "from PIL import Image\n",
        "import splitfolders\n",
        "import os\n",
        "from torchvision.datasets import ImageFolder\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "D5E8hRfWvR8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup device agnostic code"
      ],
      "metadata": {
        "id": "OjnMOIcgvs9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "HevHAo9ivpaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting dataset into train ,test and validation\n",
        "\n",
        "original=\"/content/drive/MyDrive/pytorch/ck+/CK+48\"\n",
        "splitted=\"/content/drive/MyDrive/pytorch/ck+/CK+48 splitted\"\n",
        "\n",
        "splitfolders.ratio(original,output=splitted,seed=1337,ratio=(.75,.25),group_prefix=None)"
      ],
      "metadata": {
        "id": "Jv6mx-WDwLf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XLCEQeSgwnlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/My Drive/train_test'"
      ],
      "metadata": {
        "id": "X_Gczzx3woCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To unzip files\n",
        "\"\"\"\n",
        "#Extract Zip File\n",
        "with zipfile.ZipFile('train.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('train')\n",
        "\n",
        "with zipfile.ZipFile('test.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('test')\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LhvAvEpBwwPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations, including converting to grayscale\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale with 1 channel\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485], std=[0.229]),  # Adjust mean and std for 1-channel grayscale\n",
        "])"
      ],
      "metadata": {
        "id": "9SM-OOQkybYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the root directory of your train and test data in Google Drive\n",
        "train_data_path = '/content/drive/MyDrive/train_test/train/train_d'\n",
        "test_data_path = '/content/drive/MyDrive/train_test/test/test_d'\n",
        "\n",
        "# List of emotion labels\n",
        "emotion_labels = [\n",
        "    'anger', 'contempt', 'disgust', 'fear', 'happiness', 'sadness', 'surprise'\n",
        "]"
      ],
      "metadata": {
        "id": "qAZqDQLrybOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.image_paths = [os.path.join(root, filename) for filename in os.listdir(root) if filename.endswith(\".png\")]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Manually extract the emotion label from the filename\n",
        "        emotion_label = image_path.split('/')[-1].split('_')[0]\n",
        "\n",
        "        # Handle variations in emotion labels\n",
        "        if emotion_label == 'happy':\n",
        "            emotion_label = 'happiness'\n",
        "\n",
        "        # Get the label index from the emotion_labels list\n",
        "        label = emotion_labels.index(emotion_label)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "SjWO_OYMybJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load custom train and test datasets\n",
        "train_dataset = CustomDataset(train_data_path, transform=transform)\n",
        "test_dataset = CustomDataset(test_data_path, transform=transform)"
      ],
      "metadata": {
        "id": "ypzl3v3hybE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "KdEyfZQTyrnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Access labels in the train DataLoader\n",
        "for images, labels in train_dataloader:\n",
        "    for label in labels:\n",
        "        emotion_label = emotion_labels[label]\n",
        "        print(f\"Train Emotion Label: {emotion_label}\")\n",
        "\n",
        "# Access labels in the test DataLoader\n",
        "for images, labels in test_dataloader:\n",
        "    for label in labels:\n",
        "        emotion_label = emotion_labels[label]\n",
        "        print(f\"Test Emotion Label: {emotion_label}\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pVaCBSNlyved"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader) , len(test_dataloader)"
      ],
      "metadata": {
        "id": "kcV0bEb8y4-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset) , len(test_dataset)"
      ],
      "metadata": {
        "id": "g44hDFobzMeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see the first training example\n",
        "image , label = train_dataset[0]\n",
        "image , label"
      ],
      "metadata": {
        "id": "y_eBrFRZzOL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=emotion_labels\n",
        "class_names"
      ],
      "metadata": {
        "id": "mIEG1GzCzdW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chcek the shape\n",
        "print(f\"image shape : {image.shape}\")\n",
        "print(f\"image label : {class_names[label]}\")"
      ],
      "metadata": {
        "id": "p_fC1wHJz1PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XHatcBgh0EA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your image is in the shape (3, 224, 224)\n",
        "image = image.permute(1, 2, 0)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.title(label)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NQgg98S60m5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot more images\n",
        "torch.manual_seed(42)\n",
        "fig =plt.figure(figsize = (9,9))\n",
        "rows , cols = 4,4\n",
        "for i in range(1,rows*cols+1):\n",
        "  random_idx = torch.randint(0,len(train_dataset) , size =[1]).item()\n",
        "  img , label = train_dataset[random_idx]\n",
        "  fig.add_subplot(rows,cols , i)\n",
        "  plt.imshow(img.squeeze() ,cmap=\"gray\")\n",
        "  plt.title(label)\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "IfBvkJ5B2RPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset , test_dataset"
      ],
      "metadata": {
        "id": "IZY6vOal2km7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Lets check out what we have created\n",
        "print(f\"dataloaders : {train_dataloader , test_dataloader}\")\n",
        "print(f\" length of train_dataloader : {len(train_dataloader)} batches of {batch_size}....\")\n",
        "print(f\" length of test_dataloader : {len(test_dataloader)} batches of {batch_size}...\")"
      ],
      "metadata": {
        "id": "YF_d-4_H2-pC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out whats inside the training dataloader\n",
        "train_features_batch , train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape , train_labels_batch.shape"
      ],
      "metadata": {
        "id": "wVFIQfiO3Q_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fi8FDBEB3eHk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}